### One-command install (works on $10 LicheeRV-Nano, MaixCAM, Raspberry Pi, Termux, Docker â€” anywhere PicoClaw runs)

```bash
curl -fsSL https://raw.githubusercontent.com/profbernardoj/pico-everclaw/main/setup.sh | bash
```

Then:

```bash
picoclaw onboard          # only first time â€” creates ~/.picoclaw/config.json
picoclaw gateway          # or picoclaw agent for interactive
```

Your PicoClaw instantly switches to **decentralized Morpheus inference** (GLM-5 heavy default, GLM-4.7-flash fast, Kimi K2.5, Qwen3-235b, etc.) via the local OpenAI-compatible proxy on `http://127.0.0.1:8083/v1`.

No code changes. No Docker rebuilds. No API bills. Stake MOR once â†’ unlimited use forever.

### Whatâ€™s in the repo (ready right now)

- `README.md` â€” full docs, edge-device tips, staking, troubleshooting
- `setup.sh` â€” installs EverClaw proxy + guardian + **auto-patches** `~/.picoclaw/config.json` (merges safely, backs up original)
- `config.patch.json` â€” exact model entries added (multiple Morpheus models + load-balancing ready)
- `workspace/skills/enable-morpheus/` â€” PicoClaw skill you can copy into your workspace for runtime switching
- `tools-src/morpheus-status/` â€” tiny Go-compatible status tool (just drop in if you want CLI `picoclaw tool morpheus-status`)

### What setup.sh does automatically

1. Installs full EverClaw proxy + guardian into `~/.everclaw` (same battle-tested Node.js sidecar as iron/nano-everclaw)
2. Starts it as a service (launchd / systemd / Docker-aware)
3. Runs `picoclaw onboard` if needed
4. Adds these entries to your `model_list` in `~/.picoclaw/config.json`:

```json
{
  "model_name": "morpheus-glm5",
  "model": "openai/glm-5",
  "api_base": "http://127.0.0.1:8083/v1",
  "api_key": "sk-morpheus"
},
{
  "model_name": "morpheus-flash",
  "model": "openai/glm-4.7-flash",
  "api_base": "http://127.0.0.1:8083/v1",
  "api_key": "sk-morpheus"
},
{
  "model_name": "morpheus-kimi",
  "model": "openai/kimi-k2.5",
  "api_base": "http://127.0.0.1:8083/v1",
  "api_key": "sk-morpheus"
}
```

5. Sets `agents.defaults.model = "morpheus-glm5"` (change to any above anytime)
6. Adds the `enable-morpheus` skill to your workspace so you can say `/enable-morpheus` in chat to toggle or check

### Staking (unlimited use â€” same as all EverClaw forks)

```bash
cd ~/.everclaw
node scripts/everclaw-wallet.mjs setup
node scripts/everclaw-wallet.mjs stake   # stake MOR, never spend it
```

### Test it

```bash
curl http://127.0.0.1:8083/health
picoclaw status
picoclaw agent -m "Say hello using Morpheus"
```

### Why this is perfect for PicoClawâ€™s philosophy

- PicoClaw = <10 MB RAM, <1 s startup, runs on $9.9 RISC-V  
- EverClaw proxy = separate host process (Node.js ~80 MB total with guardian)  
- Together = still the lightest decentralized AI setup on the planet  
- Works in Docker, Termux, pure binary, Sipeed boards â€” zero friction  
- Keeps sandbox, heartbeat, sub-agents, skills exactly as designed

Star the repo, run the setup, and your PicoClaw on a $10 board now has **unlimited GLM-5-class intelligence** with zero recurring cost.

Need any tweak pushed live in <60 seconds?
- Default to flash model for ultra-low-power boards?
- Full multi-model load-balancer in config?
- Native Go WASM status tool instead of skill?
- Docker-compose override?
- Move repo to your account?

Letâ€™s put decentralized inference on every $10 edge device! ðŸ¦žðŸ”¥ðŸ“¡
